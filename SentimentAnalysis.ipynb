{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB0mipJETolL"
      },
      "source": [
        "# **Importing Liabraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKSUU2zK8o7L"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "#!pip install contractions\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import contractions\n",
        "import re\n",
        "\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp709GJmTjqg"
      },
      "source": [
        "# **Data loading and Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KgZ5xTna9aeq",
        "outputId": "fb5c7759-e00f-4b1e-ea67-5e4e9c09134e"
      },
      "outputs": [],
      "source": [
        "#loading the dataset and show first 5 rows\n",
        "\n",
        "df = pd.read_csv(r'C:\\Users\\ritik\\Downloads\\archive (12)\\training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1')\n",
        "random_sample = df.sample(n=5000)\n",
        "random_sample.columns = ['sentiment','text id','Time of Tweet', 'flag', 'Account Name', 'text']\n",
        "random_sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ten3kaBB9d4m",
        "outputId": "832409fd-7a97-47e1-f2dc-f5bdb26e2274"
      },
      "outputs": [],
      "source": [
        "random_sample.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuVm6UTk9e7G",
        "outputId": "79c7c9d3-b948-4775-dc5a-ba16c9e09360"
      },
      "outputs": [],
      "source": [
        "random_sample.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDtwE__N9kyY",
        "outputId": "0ab1a2d9-59a6-4e87-a595-4463d9bdadd3"
      },
      "outputs": [],
      "source": [
        "random_sample.columns = random_sample.columns.str.strip()\n",
        "print(random_sample.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFkYeutL9orr"
      },
      "outputs": [],
      "source": [
        "#dropping blanks and unnecessary column\n",
        "random_sample = random_sample.dropna()\n",
        "random_sample = random_sample.drop(['sentiment','text id','Account Name','flag'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vx2aFv39p14",
        "outputId": "a65ad4e0-410f-46b6-aa77-4c2fb6e19c5b"
      },
      "outputs": [],
      "source": [
        "random_sample['Time of Tweet'] = pd.to_datetime(random_sample['Time of Tweet'], format='%a %b %d %H:%M:%S PDT %Y')\n",
        "random_sample.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rdUfZaUnAYpM",
        "outputId": "b162c39f-a602-41e4-9df0-8aaf19bf42f4"
      },
      "outputs": [],
      "source": [
        "random_sample.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZH_KwutTKJs"
      },
      "source": [
        "# **Text Pre - Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vp-rq4ACULJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Expand contractions\n",
        "    text = contractions.fix(text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'(http|https|www.)\\S+', '', text)\n",
        "\n",
        "    # Remove Twitter handles and hashtags\n",
        "    text = re.sub(r'[@#]\\w+', '', text)\n",
        "\n",
        "    # Tokenize the tweet\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords and punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words and word not in string.punctuation]\n",
        "\n",
        "    # Join tokens back into a sentence\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    # Remove digits\n",
        "    processed_text = re.sub(r'\\d+', '', processed_text)\n",
        "\n",
        "    # Remove non-alphabetic characters\n",
        "    processed_text = re.sub(r'[^a-zA-Z\\s]', '', processed_text)\n",
        "\n",
        "    # Remove repeated characters (e.g., \"aaah\" becomes \"ah\")\n",
        "    processed_text = re.sub(r\"(.)\\1\\1+\", r\"\\1\\1\", processed_text)\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "# Apply preprocessing to text column\n",
        "random_sample['Processed_Text'] = random_sample['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AYiFIKN9Cb8o",
        "outputId": "bf9ba1fe-197f-484c-c551-e3ae86f36483"
      },
      "outputs": [],
      "source": [
        "#checking the column\n",
        "random_sample['Processed_Text'] [:10].to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bmXMA7fsCf1Z",
        "outputId": "8dc6fe1e-ade6-41da-9642-8873daa18287"
      },
      "outputs": [],
      "source": [
        "random_sample.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGNk10k3SuQJ"
      },
      "source": [
        "# **Sentiment Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWFhbX17Cgde"
      },
      "outputs": [],
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Calculate sentiment scores\n",
        "random_sample['Sentiment_Score'] = random_sample['Processed_Text'].apply(lambda x: sid.polarity_scores(x)['compound'])\n",
        "\n",
        "# Map sentiment scores to sentiment labels\n",
        "def get_sentiment_label(score):\n",
        "    if score > 0.05:\n",
        "        return 'positive'\n",
        "    elif score < -0.05:\n",
        "        return 'negative'\n",
        "    return 'neutral'\n",
        "\n",
        "random_sample['Sentiment_Label'] = random_sample['Sentiment_Score'].apply(get_sentiment_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z9vmTLiJCnxi",
        "outputId": "243380e8-a6cb-4231-ed7b-684472d3ff35"
      },
      "outputs": [],
      "source": [
        "random_sample.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOEake06ScuD"
      },
      "source": [
        "# **Building and Evaluating SVM model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIRFaOrUCqQN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Assuming you have a DataFrame 'df' with 'Processed_Text' and 'Sentiment_Label' columns\n",
        "X = random_sample['Processed_Text']\n",
        "y = random_sample['Sentiment_Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline with TF-IDF vectorizer and SVM classifier\n",
        "model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', SVC(kernel='linear'))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43mfCCeNCuqQ"
      },
      "outputs": [],
      "source": [
        "# Experimenting with random prompt\n",
        "prompt = \"I love this specilization\"\n",
        "predicted_sentiment = model.predict([prompt])[0]\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fcNuAlUSAmb"
      },
      "source": [
        "# **Building and Evaluating Random Forest Clasifier Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klbSVGRrC0hM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Assuming you have a DataFrame 'df' with 'Processed_Text' and 'Sentiment_Label' columns\n",
        "X = random_sample['Processed_Text']\n",
        "y = random_sample['Sentiment_Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline with TF-IDF vectorizer and Random Forest classifier\n",
        "model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjNcFwqcDDWQ"
      },
      "outputs": [],
      "source": [
        "# Experimenting with random prompt\n",
        "prompt = \"today is my project reviw i wish it will go well\"\n",
        "predicted_sentiment = model.predict([prompt])[0]\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Ux7hgsRW8h"
      },
      "source": [
        "# **Building and Evaluating Naive Baye's Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeD77ccQrX2b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Assuming you have a DataFrame 'df' with 'Processed_Text' and 'Sentiment_Label' columns\n",
        "X = random_sample['Processed_Text']\n",
        "y = random_sample['Sentiment_Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline with TF-IDF vectorizer and Multinomial Naive Bayes classifier\n",
        "model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
        "\n",
        "# Example usage for making predictions on new data\n",
        "prompt = \"I love this product! It's amazing.\"\n",
        "predicted_sentiment = model.predict([prompt])[0]\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxf8LQVFU2WM"
      },
      "source": [
        "# **Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LKeQ4itUy2k"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 score']\n",
        "classifiers = ['SVM', 'RF', 'NB']\n",
        "values = [[0.92, 0.93, 0.92, 0.93], [0.89, 0.89, 0.90, 0.90], [0.73, 0.79, 0.70, 0.74]]\n",
        "colors = ['rgb(44, 160, 44)', 'rgba(255, 127, 14, 0.7)', '#1f77b4']\n",
        "\n",
        "# Plotly Interactive Bar Chart\n",
        "fig = go.Figure()\n",
        "\n",
        "for i in range(len(classifiers)):\n",
        "    fig.add_trace(go.Bar(x=metrics, y=values[i], name=classifiers[i], marker_color=colors[i]))\n",
        "\n",
        "fig.update_layout(title='Classification Report',\n",
        "                  xaxis=dict(title='Metrics'),\n",
        "                  yaxis=dict(title='Value'),\n",
        "                  barmode='group')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTj4doypsHEo"
      },
      "source": [
        "# **Distribution of Sentiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6bQLjytsMLR"
      },
      "outputs": [],
      "source": [
        "sentiment_counts = random_sample['Sentiment_Label'].value_counts()\n",
        "print(sentiment_counts)\n",
        "time_stampp = random_sample['Time of Tweet'].describe()\n",
        "print(time_stampp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqcJfPxV0Gu9"
      },
      "outputs": [],
      "source": [
        " # Bar plot for Sentiment\n",
        "plt.figure(figsize=(8, 6))\n",
        "color = sns.color_palette()[0]\n",
        "order = random_sample['Sentiment_Label'].value_counts().index\n",
        "ax = sns.countplot(data=df, x='Sentiment_Label', color=color, order=order)\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Sentiments')\n",
        "ax.bar_label(ax.containers[0], fmt='%.0f', label_type='edge')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhIAcF3MQqjP"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# **Just a Curiousity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xHr26sPWrcA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "random_sample['jesus_count'] = random_sample['Processed_Text'].apply(lambda x: x.lower().count('jesus'))\n",
        "\n",
        "# Group by sentiment label and calculate total counts\n",
        "word_counts_by_sentiment = random_sample.groupby('Sentiment_Label')[['jesus_count']].sum().reset_index()\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "word_counts_by_sentiment.plot(kind='bar', x='Sentiment_Label', ax=ax, colormap='viridis', stacked=True)\n",
        "plt.title('Word Counts by Sentiment Label')\n",
        "plt.xlabel('Sentiment Label')\n",
        "plt.ylabel('Word Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SA9KwDVQVup"
      },
      "source": [
        "## Getting the TOP 20 words by count and their weightage percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b34lxyXZNNzy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "documents = random_sample['Processed_Text']\n",
        "\n",
        "# Vectorize the text using CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=10000, stop_words='english')\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get the feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Calculate the total count for each word\n",
        "word_counts = X.sum(axis=0).A1\n",
        "\n",
        "# Create a DataFrame with words and their counts\n",
        "word_counts_df = pd.DataFrame({'Word': feature_names, 'Count': word_counts})\n",
        "\n",
        "# Sort the DataFrame by count in descending order\n",
        "word_counts_df = word_counts_df.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Calculate weighted percentages\n",
        "total_words = word_counts_df['Count'].sum()\n",
        "word_counts_df['Weighted_Percentage'] = (word_counts_df['Count'] / total_words) * 100\n",
        "\n",
        "# Get the top 20 words\n",
        "top_20_words = word_counts_df.head(20)\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "top_20_words.plot(kind='bar', x='Word', y='Count', ax=ax, colormap='viridis')\n",
        "ax2 = ax.twinx()\n",
        "top_20_words.plot(kind='line', x='Word', y='Weighted_Percentage', ax=ax2, color='orange', marker='o')\n",
        "ax.set_title('Top 20 Words with Counts and Weighted Percentages')\n",
        "ax.set_ylabel('Count')\n",
        "ax2.set_ylabel('Weighted Percentage', color='orange')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2Xu5MfiP5tJ"
      },
      "source": [
        "# Generating Word cloud for better visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqUtcN43ulIn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "text_data = ' '.join(random_sample['Processed_Text'])\n",
        "\n",
        "# Generate the word cloud with customizations\n",
        "wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    random_state=42,\n",
        "    background_color='black',\n",
        "    colormap='inferno',  # Use a different colormap\n",
        "    contour_color='steelblue',  # Color of the word cloud outline\n",
        "    contour_width=2,  # Width of the word cloud outline\n",
        "    max_words=200,  # Maximum number of words in the cloud\n",
        ").generate(text_data)\n",
        "\n",
        "# Display the word cloud using matplotlib\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
